{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fallstudie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Pakete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sqlalchemy import create_engine \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Datenbank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cnx = create_engine('sqlite:///C:/Users/Kilian/Notebook/VisualStudio_projekte/Fallstudie/Kundendaten.db').connect() \n",
    "\n",
    "  \n",
    "df = pd.read_sql_table('testdaten', cnx) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.head(100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datenmodellierung "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"Datum\"], 1)\n",
    "df = df.drop([\"Anzahl\"], 1)\n",
    "df = df.drop([\"Gewinn\"], 1)\n",
    "df = df.drop([\"Jahr\"], 1)\n",
    "df = df.drop([\"Monat\"], 1)\n",
    "df = df.drop([\"Tag\"], 1)\n",
    "df = df.drop([\"index\"], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Alter Geschlecht                  Job         Familienstand Kinder  \\\n",
       "0     47          M  Öffentlicher Dienst           verheiratet     ja   \n",
       "1     45          M      Ingenieurswesen           verheiratet     ja   \n",
       "2     23          W             Handwerk                 ledig   nein   \n",
       "3     60          W        Administrativ           verheiratet     ja   \n",
       "4     60          M           Informatik  aufgelöste Beziehung     ja   \n",
       "\n",
       "     Gehalt Angebotenes Produkt Gekauft  \n",
       "0   42000.0          Depotkonto    nein  \n",
       "1   76000.0      Bausparvertrag      ja  \n",
       "2   23000.0              Kredit    nein  \n",
       "3   57000.0              Kredit    nein  \n",
       "4  123000.0              Kredit    nein  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Alter</th>\n      <th>Geschlecht</th>\n      <th>Job</th>\n      <th>Familienstand</th>\n      <th>Kinder</th>\n      <th>Gehalt</th>\n      <th>Angebotenes Produkt</th>\n      <th>Gekauft</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>47</td>\n      <td>M</td>\n      <td>Öffentlicher Dienst</td>\n      <td>verheiratet</td>\n      <td>ja</td>\n      <td>42000.0</td>\n      <td>Depotkonto</td>\n      <td>nein</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>45</td>\n      <td>M</td>\n      <td>Ingenieurswesen</td>\n      <td>verheiratet</td>\n      <td>ja</td>\n      <td>76000.0</td>\n      <td>Bausparvertrag</td>\n      <td>ja</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>23</td>\n      <td>W</td>\n      <td>Handwerk</td>\n      <td>ledig</td>\n      <td>nein</td>\n      <td>23000.0</td>\n      <td>Kredit</td>\n      <td>nein</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>60</td>\n      <td>W</td>\n      <td>Administrativ</td>\n      <td>verheiratet</td>\n      <td>ja</td>\n      <td>57000.0</td>\n      <td>Kredit</td>\n      <td>nein</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>60</td>\n      <td>M</td>\n      <td>Informatik</td>\n      <td>aufgelöste Beziehung</td>\n      <td>ja</td>\n      <td>123000.0</td>\n      <td>Kredit</td>\n      <td>nein</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 245
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "df[\"Altersgruppe\"] = \">65\"\n",
    "\n",
    "df[\"Altersgruppe\"][df[\"Alter\"] > 65] = \">65\"\n",
    "df[\"Altersgruppe\"][(df[\"Alter\"] >= 50) & (df[\"Alter\"] < 65)] = \"50 - 65\"\n",
    "df[\"Altersgruppe\"][(df[\"Alter\"] >= 30) & (df[\"Alter\"] < 50)] = \"30 - 49\"\n",
    "df[\"Altersgruppe\"][(df[\"Alter\"] >= 18) & (df[\"Alter\"] < 30)] = \"18 - 29\"\n",
    "df[\"Altersgruppe\"][df[\"Alter\"] < 18] = \"<18\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"balance_cat\"] = \"> 100000\"\n",
    "\n",
    "df[\"balance_cat\"][df[\"Gehalt\"] > 100000] = \"> 100000\"\n",
    "df[\"balance_cat\"][(df[\"Gehalt\"] >= 80000) & (df[\"Gehalt\"] < 100000)] = \"80000 - 99999\"\n",
    "df[\"balance_cat\"][(df[\"Gehalt\"] >= 60000) & (df[\"Gehalt\"] < 80000)] = \"60000 - 79999\"\n",
    "df[\"balance_cat\"][(df[\"Gehalt\"] >= 40000) & (df[\"Gehalt\"] < 60000)] = \"40000 - 59999\"\n",
    "df[\"balance_cat\"][(df[\"Gehalt\"] >= 20000) & (df[\"Gehalt\"] < 40000)] = \"20000 - 39999\"\n",
    "df[\"balance_cat\"][(df[\"Gehalt\"] >= 0) & (df[\"Gehalt\"] < 20000)] = \"0 - 19999\"\n",
    "df[\"balance_cat\"][df[\"Gehalt\"] < 0] = \"< 0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Produkt\"] = df[\"Angebotenes Produkt\"]\n",
    "df[\"Produkt\"] = df[\"Produkt\"].replace([\"Girokonto\", \"Kredit\",\"Tagesgeldkonto\",\"Depotkonto\", \"Altersvorsorge\",\"Versicherung\", \"Bausparvertrag\"],[1,2,3,4,5,6,7])\n",
    "df = df.drop([\"Angebotenes Produkt\"], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df[\"Job\"] = df[\"Job\"].replace([\"Studium\", \"Öffentlicher Dienst\", \"Rente\", \"Informatik\", \"Handel\", \"Handwerk\", \"Administrativ\", \"Ingenieurswesen\", \"Management\", \"Arbeitslos\"],[0,1,2,3,4,5,6,7,8,9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Geschlecht\"] = df[\"Geschlecht\"].replace([\"M\", \"W\", \"D\"],[1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Familienstand\"] = df[\"Familienstand\"].replace([\"verheiratet\", \"ledig\", \"aufgelöste Beziehung\"],[1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Kinder\"] = df[\"Kinder\"].replace([\"ja\", \"nein\"],[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Altersgruppe\"] = df[\"Altersgruppe\"].replace([\"<18\", \"18 - 29\", \"30 - 49\", \"50 - 65\", \">65\"],[0,1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"balance_cat\"] = df[\"balance_cat\"].replace([\"< 0\", \"0 - 19999\", \"20000 - 39999\", \"40000 - 59999\", \"60000 - 79999\", \"80000 - 99999\", \"> 100000\"],[1,2,3,4,5,6,7])\n",
    "df = df.drop([\"Gehalt\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"Alter\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Gekauft\"] = df[\"Gekauft\"].replace([\"nein\", \"ja\"],[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(df[\"Gekauft\"])\n",
    "#labels = np.array(df[\"Produkt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTest = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"Gekauft\"], axis=1)\n",
    "#df = df.drop([\"Produkt\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = list(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithmen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainings- und Testdaten vorbereiten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = np.array(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, train_labels, test_labels = train_test_split(df, labels, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Features Shape: (285519, 7)\nTraining Labels Shape: (285519,)\nTesting Features Shape: (95173, 7)\nTesting Labels Shape: (95173,)\n"
     ]
    }
   ],
   "source": [
    "print('Training Features Shape:', train_data.shape)\n",
    "print('Training Labels Shape:', train_labels.shape)\n",
    "print('Testing Features Shape:', test_data.shape)\n",
    "print('Testing Labels Shape:', test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RANDOM FOREST CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators = 1000, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rf.fit(train_data, train_labels);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred_rf = rf.predict(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "#errors_rf = abs(pred_rf - test_labels)\n",
    "#errors_rf = [x for x in errors_rf if x != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(f\"Accuracy RF = {(len(test_labels)-len(errors_rf))/len(test_labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion_matrix_rf = sklearn.metrics.confusion_matrix(test_labels, pred_rf)\n",
    "#tn_rf, fp_rf, fn_rf, tp_rf = confusion_matrix_rf.ravel()\n",
    "\n",
    "#Precision_rf = tp_rf/(tp_rf+fp_rf)\n",
    "#Recall_rf = tp_rf/(tp_rf+fn_rf)\n",
    "#F1_rf = 2*((Precision_rf*Recall_rf)/(Precision_rf+Recall_rf))\n",
    "\n",
    "#print(f\"Precision RF = {Precision_rf}\")\n",
    "#print(f\"Recall Rf = {Recall_rf}\")\n",
    "#print(f\"F1 Score RF = {F1_rf}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K NEAREST NEIGHBORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classifier = KNeighborsClassifier(n_neighbors=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classifier.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred_knn = classifier.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "#errors_knn = abs(pred_knn - test_labels)\n",
    "#errors_knn = [x for x in errors_knn if x != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(f\"Accuracy KNN = {(len(test_labels)-len(errors_knn))/len(test_labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion_matrix_knn = sklearn.metrics.confusion_matrix(test_labels, pred_knn)\n",
    "#tn_knn, fp_knn, fn_knn, tp_knn = confusion_matrix_knn.ravel()\n",
    "\n",
    "#Precision_knn = tp_knn/(tp_knn+fp_knn)\n",
    "#Recall_knn = tp_knn/(tp_knn+fn_knn)\n",
    "#F1_knn = 2*((Precision_knn*Recall_knn)/(Precision_knn+Recall_knn))\n",
    "\n",
    "#print(f\"Precision KNN = {Precision_knn}\")\n",
    "#print(f\"Recall KNN = {Recall_knn}\")\n",
    "#print(f\"F1 Score KNN = {F1_knn}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    " from scipy import stats\n",
    " from scipy.stats import randint\n",
    " from sklearn.model_selection import RandomizedSearchCV\n",
    " from sklearn.metrics import precision_score,recall_score,accuracy_score,f1_score,roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(\n",
    " objective= 'binary:logistic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {'n_estimators': stats.randint(150, 1000),\n",
    "              'learning_rate': stats.uniform(0.01, 0.6),\n",
    "              'subsample': stats.uniform(0.3, 0.9),\n",
    "              'max_depth': [3, 4, 5, 6, 7, 8, 9],\n",
    "              'colsample_bytree': stats.uniform(0.5, 0.9),\n",
    "              'min_child_weight': [1, 2, 3, 4]\n",
    "             }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomizedSearchCV(model, \n",
    "                         param_distributions = param_dist,\n",
    "                         n_iter = 5,\n",
    "                         scoring = 'roc_auc', \n",
    "                         error_score = 0, \n",
    "                         verbose = 3, \n",
    "                         n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  19 out of  25 | elapsed:   27.8s remaining:    8.7s\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed: 12.7min finished\n",
      "[18:31:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=None, error_score=0,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None, gamma=None,\n",
       "                                           gpu_id=None, importance_type='gain',\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate=None,\n",
       "                                           max_delta_step=None, max_depth=None,\n",
       "                                           min_child_weight=None, missing=nan,\n",
       "                                           monotone_constraints=None,...\n",
       "                                        'learning_rate': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000002AB332B78C8>,\n",
       "                                        'max_depth': [3, 4, 5, 6, 7, 8, 9],\n",
       "                                        'min_child_weight': [1, 2, 3, 4],\n",
       "                                        'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000002AB337ED0C8>,\n",
       "                                        'subsample': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000002AB3701DB08>},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring='roc_auc', verbose=3)"
      ]
     },
     "metadata": {},
     "execution_count": 280
    }
   ],
   "source": [
    "clf.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_xgb = clf.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_xgb = abs(pred_xgb - test_labels)\n",
    "errors_xgb = [x for x in errors_xgb if x != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy XGB = 0.7209502695092096\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy XGB = {(len(test_labels)-len(errors_xgb))/len(test_labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Precision xgb = 0.6007807684405178\nRecall xgb = 0.20504908835904628\nF1 Score xgb = 0.3057458043603283\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix_xgb = sklearn.metrics.confusion_matrix(test_labels, pred_xgb)\n",
    "tn_xgb, fp_xgb, fn_xgb, tp_xgb = confusion_matrix_xgb.ravel()\n",
    "\n",
    "Precision_xgb = tp_xgb/(tp_xgb+fp_xgb)\n",
    "Recall_xgb = tp_xgb/(tp_xgb+fn_xgb)\n",
    "F1_xgb = 2*((Precision_xgb*Recall_xgb)/(Precision_xgb+Recall_xgb))\n",
    "\n",
    "print(f\"Precision xgb = {Precision_xgb}\")\n",
    "print(f\"Recall xgb = {Recall_xgb}\")\n",
    "print(f\"F1 Score xgb = {F1_xgb}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funktion für Applikation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NotFittedError",
     "evalue": "need to call fit or load_model beforehand",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-285-d2659006a512>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m      \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mvorschlag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkunde\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, data, ntree_limit, validate_features, base_margin)\u001b[0m\n\u001b[0;32m   1027\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mntree_limit\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1028\u001b[0m             \u001b[0mntree_limit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"best_ntree_limit\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1029\u001b[1;33m         class_probs = self.get_booster().predict(test_dmatrix,\n\u001b[0m\u001b[0;32m   1030\u001b[0m                                                  \u001b[0mntree_limit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mntree_limit\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m                                                  validate_features=validate_features)\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mget_booster\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    309\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_Booster'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m             \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'need to call fit or load_model beforehand'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Booster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFittedError\u001b[0m: need to call fit or load_model beforehand"
     ]
    }
   ],
   "source": [
    "for x in range(1,8):\n",
    "     print(model.predict_proba(np.array([[2,0,2,0,1,2,x]])).reshape((1,-1)))\n",
    "        \n",
    "        \n",
    "def vorschlag(kunde):\n",
    "    kunde = np.array(kunde).reshape((1,-1))\n",
    "    \n",
    "    kunde[0][6] = 1\n",
    "    prob1 = model.predict_proba(kunde)[0][1]\n",
    "    \n",
    "    kunde[0][6] = 2\n",
    "    prob2 = model.predict_proba(kunde)[0][1]\n",
    "    \n",
    "    kunde[0][6] = 3\n",
    "    prob3 = model.predict_proba(kunde)[0][1]\n",
    "    \n",
    "    kunde[0][6] = 4\n",
    "    prob4 = model.predict_proba(kunde)[0][1]\n",
    "    \n",
    "    kunde[0][6] = 5\n",
    "    prob5 = model.predict_proba(kunde)[0][1]\n",
    "    \n",
    "    kunde[0][6] = 6\n",
    "    prob6 = model.predict_proba(kunde)[0][1]\n",
    "    \n",
    "    kunde[0][6] = 7\n",
    "    prob7 = model.predict_proba(kunde)[0][1]\n",
    "    \n",
    "    produkt = {\"Girokonto\":prob1,\"Kredit\":prob2, \"Tagesgeldkonto\":prob3, \"Depotkonto\":prob4, \"Altersvorsorge\":prob5, \"Versicherung\":prob6, \"Bausparvertrag\":prob7}\n",
    "    \n",
    "    print(f\"Top 3 Produktvorschläge:\")\n",
    "    print(f\"1. {sorted(produkt, key=produkt.get, reverse=True)[:3][0]} mit {round((produkt.get(sorted(produkt, key=produkt.get, reverse=True)[:3][0])*100),2)}% Erfolgschance\")\n",
    "    print(f\"2. {sorted(produkt, key=produkt.get, reverse=True)[:3][1]} mit {round((produkt.get(sorted(produkt, key=produkt.get, reverse=True)[:3][1])*100),2)}% Erfolgschance\")\n",
    "    print(f\"3. {sorted(produkt, key=produkt.get, reverse=True)[:3][2]} mit {round((produkt.get(sorted(produkt, key=produkt.get, reverse=True)[:3][2])*100),2)}% Erfolgschance\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Top 3 Produktvorschläge:\n1. Girokonto mit 39.32% Erfolgschance\n2. Depotkonto mit 18.78% Erfolgschance\n3. Versicherung mit 14.11% Erfolgschance\n"
     ]
    }
   ],
   "source": [
    "vorschlag(np.array([[2,0,2,0,1,2,x]]).reshape((1,-1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'jungbank_xgb.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Geschlecht  Job  Familienstand  Kinder  Gekauft  Altersgruppe  balance_cat  \\\n",
       "0           1    1              1       1        0             2            4   \n",
       "1           1    7              1       1        1             2            5   \n",
       "2           2    5              2       0        0             1            3   \n",
       "3           2    6              1       1        0             3            4   \n",
       "4           1    3              3       1        0             3            7   \n",
       "\n",
       "   Produkt  \n",
       "0        4  \n",
       "1        7  \n",
       "2        2  \n",
       "3        2  \n",
       "4        2  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Geschlecht</th>\n      <th>Job</th>\n      <th>Familienstand</th>\n      <th>Kinder</th>\n      <th>Gekauft</th>\n      <th>Altersgruppe</th>\n      <th>balance_cat</th>\n      <th>Produkt</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>4</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>7</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>5</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>5</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>6</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>4</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>3</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>7</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 89
    }
   ],
   "source": [
    "dfTest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.7 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "98a05330b4f2ad7866d28621da417a632153f77c97e02c99d8b84bdecf288633"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}